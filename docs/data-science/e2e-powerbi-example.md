---
title: E2E Power BI example
description: End-to-end example of data science capabilities when interacting with Power BI.
ms.reviewer: mopeakande
ms.author: narsam
author: narmeens
ms.topic: how-to
ms.date: 02/10/2023
---

# E2E Power BI example

> [!IMPORTANT]
> [!INCLUDE [product-name](../includes/product-name.md)] is currently in PREVIEW. This information relates to a prerelease product that may be substantially modified before it's released. Microsoft makes no warranties, expressed or implied, with respect to the information provided here.

This demo is designed for private preview of Azure Synapse data science capabilities, including, but not limited to, interaction with Power BI and new semantic modeling features of a python package called SemPy developed for making it easier to capture and share domain knowledge.

## Setup

It usually takes about a minute to start the session. Hang tight!

Here we're importing necessary packages and setting up environment variables.

```python
import sempy  
import os
import pandas as pd
import sys

from pathlib import Path

from sempy.connectors.powerbi import PowerBIConnector

os.environ['PATH'] = f"{Path(sys.executable).parent}:"+os.environ['PATH'] 
pd.options.display.max_colwidth = 200
```

## Part 0. Connect to Power BI

Here we're pulling data from a Synapse workspace with Power BI connector:

```python
conn = PowerBIConnector() 
conn.get_datasets()
```

For the rest of this notebook, we'll focus on "Customer Profitability Sample PBIX" in two different flavors.

1. The dataset as it comes from Power BI samples - with predefined table relations: **Customer Profitability Sample PBIX**
1. The dataset after manually  removing all table relations and adding relationships auto-detected by Power BI prior to importing PBIX file to Synapse: **Customer Profitability Sample PBIX (auto)**

## Part 1. Extract a sample dataset with its predefined semantic model

```python
kb1 = conn.load_dataset("Customer Profitability Sample PBIX") 
```

We pulled the data and semantic model from Power BI and persisted it in the SemPy knowledge base (kb1).

```python
kb1.plot_relationships()
```

This is "ground truth" for relationships between tables in this dataset, as it reflects how they were defined by a subject matter expert in Power BI.

```python
customer_df =  kb1.get_data("Customer")
customer_df.head()
```

Let's now take advantage of knowing the relationships between tables and use SemPy to help merge the customer table with state table, storing results in another dataframe:

```python
customer_state_df = customer_df.merge("State",  how='left')
customer_state_df.head()
```

We can even join tables that aren't related directly, and render the path that SemPy used for this as follows:

```python
fact_df =  kb1.get_data("Fact")
fact_state_df = fact_df.merge("State", show_path=True)
```

```python
fact_state_df.head()
```

As you can see, the dataframe supports the standard pandas interface for output - head(). It supports other functions and has added semantic capabilities, and we'll explore it further in Part 3 of the demo.

## Part 2. Complement relationships discovery

```python
kb2 = conn.load_dataset("Customer Profitability Sample PBIX (auto)") 
kb2.plot_relationships()
```

As we see, Power BI autodetection missed many relationships. Moreover, two of auto-detected relationships are semantically incorrect: BU(Executive_id)->Industry(ID) and Executive(ID)->Industry(ID).

```python
relationships_powerbi= kb2.get_relationships()
[print(i, item) for (i, item) in enumerate(relationships_powerbi, start=0)];
```

Let's get rid of incorrectly identified relationships.

```python
kb2.delete(relationships_powerbi[3])
kb2.delete(relationships_powerbi[4])
```

After this cleanup, we've correct, but incomplete relationships:

```python
kb2.plot_relationships()
```

Now let's see if we can do better with SemPy tools.

```python
suggested_relationships_all = kb2.find_relationships(attribute_similarity_threshold=0.7, coverage_threshold=0.7, verbose=2);
```

Great, looks like SemPy was able to detect all relationships! Let's find just the ones that don't already exist in the knowledge base.

```python
suggested_relationships = kb2.find_relationships(attribute_similarity_threshold=0.7, exclude_existing=True, coverage_threshold=0.7)
suggested_relationships
```

Looks good. Adding those to the knowledge base and displaying resulting schema below.

```python
kb2.add_relationships(suggested_relationships)
kb2.plot_relationships()
```

## Part 3. Explore and clean data

Let's start with validating relationships. Firstly, do we have complete overlaps between the primary and foreign key values?

```python
kb1.list_relationship_violations()
```

This provides us with interesting insights, such as the fact that one out of seven values in Fact[Product Key] isn't present in Product[Product Key], and this missing key is 50.

Let's take a closer look at the structure of semantic dataframe generated by SemPy by merging Customer and State tables:

```python
customer_state_df.column_group.pprint()
```

Can it also identify functional dependencies between values in the columns? Let's see:

```python
customer_state_df.plot.dependencies()
```

It's bizarre that we didn't detect functional dependencies between City and postal code. There probably are many violations. Let's explore:

```python
customer_state_df.plot_dependency_violations('Postal Code', 'City')
```

Indeed, quite a few violations. Moreover, there are many empty values.

```python
customer_state_df['Postal Code'].isna().sum()
```

50 rows have NA for postal code, to be precise. Let's try to detect dependencies after getting rid of empty values:

```python
customer_state_df2=customer_state_df.dropna()
customer_state_df2.find_dependencies(verbose=1);
```

Now conditional entropy is 0.049, which makes sense, since we saw violations. We can fix violations. But before we did, just to see the dependencies, we can explicitly raise the threshold as follows:

```python
customer_state_df2.plot.dependencies(threshold=0.05)
```

Okay, this is more like it, if you think of the domain from the perspective of which entity should determine values of other entities.

Let's explore more data quality issues that we detected. For example, what's going on with City and Region that causes the line to be dotted, implying existence of partial functional dependencies?

```python
customer_state_df.list_dependency_violations('City', 'Region')
```

Going deeper into each of the cases where we see non-empty Region value that causes violations:

```python
customer_state_df[customer_state_df.City=='Downers Grove']
```

Downers Grove definitely is in Illinois, not Nebraska. See wiki: [https://en.wikipedia.org/wiki/Downers_Grove,_Illinois](https://en.wikipedia.org/wiki/Downers_Grove,_Illinois) ("It was founded in 1832 by Pierce Downer, whose surname serves as the eponym for the village"). Great catch of data consistency issue!

```python
customer_state_df[customer_state_df.City=='Fremont']
```

There's a city called Fremont in California ([https://en.wikipedia.org/wiki/Fremont,_California](https://en.wikipedia.org/wiki/Fremont,_California)). However, for Texas, the search engine returns Premont, not Fremont ([https://en.wikipedia.org/wiki/Premont,_Texas](https://en.wikipedia.org/wiki/Premont,_Texas))! Interesting error in the data, and awesome that we were able to catch it automatically.

It's also suspicious to see violations of "Name" and "Country/Region" dependency, signified by dotted line.

```python
customer_state_df.list_dependency_violations('Name', 'Country/Region')
```

Seems like have one customer, 'SDI Design' who's present in two regions - United States and Canada. This doesn't look like a semantic violation, just an uncommon case, but let's take a closer look at them

```python
customer_state_df[customer_state_df.Name=='SDI Design']
```

It's actually different customers with the same name - coming different industries... Again, doesn't seem wrong, just a collision of names.

We can continue diving into this data in this fashion, discovering nontrivial data quality issues with the help of functional dependency detection capability from SemPy.

```python
cptypes=kb1.get_compound_stypes()
["Entity: "+str(i)+" "+str(kb1.get_stype(i).get_components()) for i in cptypes]
```

With semantic data frames, we can also get some out-of-box visualizations without having to worry about plotting functions in python, such as histograms of distribution of Postal Codes and Industry IDs within customer_df table - see the following:

```python
customer_df.plot.numeric(['Postal Code', 'Industry ID'])
```

```python
customer_state_df.plot.categories(['Region'])
```

Moreover, if we want to have some more advanced insights - e.g. try to understand main characteristics of customers in different industries, we can ask SemPy to make an attempt to build a classification model! Below you can see analytical visualizations that you would normally have to build manually, one by one, in order to assess the data for modeling.

```python
customer_state_df.plot.classification(target_column='Industry ID')
```

Exploratory data analysis is an exciting process, and so is data cleaning ;-) There's always something that the data is hiding, depending on how you look at it, what you want to ask, and so on. We're hoping that with the new tools you can achieve more.
