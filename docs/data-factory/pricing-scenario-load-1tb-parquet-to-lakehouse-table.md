---
title: Pricing scenario - Data pipelines load 1 TB of Parquet data to a Lakehouse table
description: This article provides an example pricing scenario for loading 1 TB of Parquest data to a Lakehouse table using Data Factory in Microsoft Fabric.
ms.reviewer: jonburchel
ms.author: adija
author: adityajain2408
ms.topic: conceptual
ms.date: 10/31/2023
---

# Pricing scenario using a data pipeline to load 1 TB of Parquet data to a Lakehouse table

In this scenario, a Copy activity was used in a data pipeline to load 1 TB of Parquet data stored in ADLS Gen2 to a Lakehouse table in Microsoft Fabric.

The prices used in the following example are hypothetical and donâ€™t intend to imply exact actual pricing. These are just to demonstrate how you can estimate, plan, and manage cost for Data Factory projects in Microsoft Fabric. Also, since Fabric capacities are priced uniquely across regions, we will be using the pay-as-you-go pricing for a Fabric capacity at US West 2 (a typical Azure region), at $0.18 per CU per hour. Refer here to [Microsoft Fabric - Pricing](https://azure.microsoft.com/pricing/details/microsoft-fabric/) to explore other Fabric capacity pricing options.

## Configuration

## Manual cost estimation

## Cost estimation using the Fabric Metrics App

## Next steps

- [Data pipelines pricing for Data Factory in Microsoft Fabric](pricing-pipelines.md)
- [Dataflows Gen2 pricing for Data Factory in Microsoft Fabric](pricing-dataflows-gen2.md)
- [Pricing example scenarios](pricing-overview.md#pricing-examples)
