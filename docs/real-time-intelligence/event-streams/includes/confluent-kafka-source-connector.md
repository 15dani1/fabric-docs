---
title: Confluent Kafka connector for Fabric event streams
description: This include files has the common content for configuring Confluent Kafka connector for Fabric event streams and Real-Time hub. 
ms.author: xujiang1
author: xujxu 
ms.topic: include
ms.custom:
  - build-2024
ms.date: 04/18/2024
---


1. Select Confluent as the source type. 
1. Enter the information of your Confluent Cloud Kafka.  
    1. Confluent Bootstrap Server: Go to your Confluent Cloud home page, select Cluster Settings, and copy the address to your Bootstrap Server.  
    1. Connection name: Automatically generated by the eventstream.  
    1. API Key and Secret: Go to your Confluent Cloud and select API Keys on the side menu. Select the **Add key** button to create a new API key. Then copy the API Key and Secret to complete the eventstream connection credentials.  
1. Next, enter the information to complete the configuration of the Confluent data source. 
    1. **Source name**: Enter a name for this eventstream source. 
    1. **Topic name**: Enter a topic name from your Confluent Cloud. You can create or manage your topic in the Confluent Cloud Console. 
    1. **Consumer group**: Enter a consumer group of your Confluent Cloud. It provides you with the dedicated consumer group for getting the events from Confluent Cloud cluster. 
    1. **Auto offset reset setting**: You can specify a time when the eventstream starts streaming data. There are three options: 1) Earliest – the earliest data available from your Confluent cluster; 2) Latest – the latest available data; 3) None – don't automatically set the offset.  
1. Review the summary and select Confirm to complete the configuration. Then you can see a Confluent Cloud Kafka source added to your eventstream in the editor. 

 