---
title: Confluent Kafka connector for Fabric event streams
description: This include files has the common content for configuring Confluent Kafka connector for Fabric event streams and Real-Time hub. 
ms.author: xujiang1
author: xujxu 
ms.topic: include
ms.custom:
  - build-2024
ms.date: 04/18/2024
---


1. Select **Confluent** as the source type. 
1. Enter the information of your Confluent Cloud Kafka.  
    - **Confluent Bootstrap Server**: Go to your Confluent Cloud home page, select Cluster Settings, and copy the address to your Bootstrap Server.  
    - **Connection name**: Automatically generated by the eventstream.  
    - **API Key and Secret**: Go to your Confluent Cloud and select API Keys on the side menu. Select the **Add key** button to create a new API key. Then copy the API Key and Secret to complete the eventstream connection credentials.  
1. Next, enter the information to complete the configuration of the Confluent data source. 
    - **Source name**: Enter a name for this eventstream source. 
    - **Topic name**: Enter a topic name from your Confluent Cloud. You can create or manage your topic in the Confluent Cloud Console. 
    - **Consumer group**: Enter a consumer group of your Confluent Cloud. It provides you with the dedicated consumer group for getting the events from Confluent Cloud cluster. 
    - **Auto offset reset setting**: You can specify a time when the eventstream starts streaming data. There are three options: 
        - **Earliest** – the earliest data available from your Confluent cluster
        - **Latest** – the latest available data
        - **None** – don't automatically set the offset.  
1. Review the summary and select Confirm to complete the configuration. Then you can see a Confluent Cloud Kafka source added to your eventstream in the editor. 

 