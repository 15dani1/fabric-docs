### YamlMime:FAQ
metadata:
  title: Spark workplace administration settings FAQ
  description: Answers to frequently asked questions about Spark workplace administration settings.
  author: santhoshravindran7
  ms.author: saravi
  ms.topic: faq
  ms.date: 02/24/2023
title: Spark workplace administration settings FAQ
summary: |
  Find answers to frequently asked questions about Spark workplace administration settings.

sections:
  - name: Workplace administration settings
    questions:
      - question: How do I use the RBAC roles to configure my workspace Spark settings? 
        answer: Manage Access menu can be used to add “Admin” permissions for specific users, distribution or security groups to make changes to the workspace, to enable the access to add, modify or delete the workspace Spark settings.

      - question: How do I ensure the changes made at the workspace level for theSpark properties don't impact active notebook sessions, or scheduled Spark jobs?
        answer: Every time a configuration changes made at the workspace level, it will not impact active Spark sessions (batch or notebook based) and you would need to start a new notebook or batch session after the saving the new configuration settings to take effect.

      - question: Can I configure the Node Family, Spark Runtime and Spark Properties at a Capacity level?
        answer: For Private preview, Spark Administration settings are only enabled at the workspace level.

      - question: Can I choose different node families for different notebooks and Spark job definitions in my workspace?
        answer: For private preview, users can only select either a Memory Optimized (Default) or a Hardware Accelerated GPU based node family for the entire workspace. Users won't be able to select Hardware Accelerated GPU based pools for specific notebooks in a workspace. Users would need to create a new workspace or modify node family settings for the current workspace  to “Hardware Accelerated GPU” based pools for compute intensive workloads.

      - question: What versions of Spark are supported?
        answer: For private preview, Spark version 3.2 is the only version that's supported. In the upcoming release, support for additional versions of Spark will be available.

      - question: Can I configure these settings at a notebook level?
        answer: Currently, for Private preview, the Spark Administration settings are enabled only at the workspace level.

      - question: Can I configure the min and max number of nodes for the selected node family? How do I enable Autoscaling for the Spark Pools in a memory optimized or hardware accelerated GPU based Node Family?
        answer: For the private preview version, node limit configuration and autoscaling aren't enabled as part of the workspace configuration settings to users. These capabilities will be enabled as part of the future releases.

      - question: Is Intelligent Caching for the Spark Pools supported or enabled by default for a workspace?
        answer: Intelligent Caching is enabled by default for the Spark pools for all workspaces as part of private preview.
